%----------------------------------------------------------------------------
\chapter{Eredmények}
%----------------------------------------------------------------------------

Ebben a fejezetben az elért eredményeket összesítem és értékelem a megoldásom.

Az előző fejezet elején bemutattam az első jelenetet, amit teszteléshez használtam. Ez 178db $640\times 480$-as felbontású képből állt, melyeken két teásdobozt mozgattam, ezek mérete összesen kb. a képek területének 15\%-át tették ki. A bemutatott képeken jól látszódott, hogy a helyreállítás minősége a mélységet bemutató színábrázolással szemléltetve is nagyon jó lett, melyet az átlagos visszavetítési hibák (melyek átlaga 0,806 pixel lett) is jól alátámasztottak.

Ahogy a korábbi fejezetekben említésre került, a választott megoldáshoz szükséges, hogy az objektumok jól textúrázottak legyenek, valamint azért, hogy a különböző objektumokat elkülöníthessem, egymáshoz képest is eltérő leírókkal (alak, szín, textúra jellege) kell rendelkezniük. Ezek az én esetemben nagyjából teljesültek, egyedül az egyik teásdoboz volt néhol túl homogén, de ez jól bemutatta a megoldás ezen korlátját.

A kezdeti 1 FPS-es sebességből párhuzamosítás és GPU-n történő gyorsítás után egészen 
3,86 FPS-re sikerült gyorsítani ugyanazon jeleneten a feldolgozás sebességét, amely jelentős növekedést jelentett. Megvizsgáltam azt is, hogy kisebb képek esetén, mennyire közelíthető meg a kívánt valós idejű feldolgozás. A tesztek alapján úgy találtam, hogy az általam rendelkezésre álló hardveren a készített megoldás még az értékelhető $160\times 140$-es felbontás körüli képrészletekből jó minőségűnek vélt helyreállítást készített (ámbátor már jelentősebb, 5 pixeles átlagos visszavetítési hibával), és elérte a 12 FPS-es sebességet. De az elérni kívánt másodpercenkénti \textasciitilde 24 képkocka feldolgozását nem sikerült megközelíteni, ennél kisebb képeken pedig már nem volt gyakorlati haszna kísérletezni. Ezen eredményeket összefoglalóan \aref{table:results}. táblázat mutatja be. Fontos megemlíteni, hogy a sebesség különbség az utolsó 2-2 esetben abból adódik, hogy amikor az eredeti kép egy részletét vizsgáltam, akkor a kép legnagyobb részét maga az objektum tette ki, míg a legkicsinyített verzióban csak egy kis részét.

\begin{table}[tbh]
\centering

\begin{tabular}{|l|l|l|}
\hline
\textbf{Módszer} & \textbf{Felbontás} & \textbf{Átlagos sebesség} \\ \hline\hline

Egyszálon, CPU-n & $640\times 480$ & 1,1 FPS \\ \hline
Többszálon, CPU-n & $640\times 480$ & 2,56 FPS \\ \hline
Többszálon, GPU-n is & $640\times 480$ & \textbf{3,86 FPS} \\ \hline\hline

Eredeti kép kicsinyítve & $320\times 240$ & 10,1 FPS \\ \hline
Eredeti kép kicsinyítve & $160\times 120$ & 14,3 FPS \\ \hline\hline

Eredeti kép egy részlete & $320\times 240$ & 7,7 FPS \\ \hline
Eredeti kép egy részlete & $160\times 140$ & \textbf{12 FPS} \\ \hline

\end{tabular}

\caption{Egyes módszerek és különböző felbontás esetén az átlagosan elért sebességek \label{table:results}}
\end{table}

A fentiek tükrében a feladat megoldása sikeresen, a kitűzött célt elérve valósult meg.

%----------------------------------------------------------------------------
\section{Továbbfejlesztési lehetőségek}
%----------------------------------------------------------------------------

\Aref{table:result_scene1_multi_gpu}. táblázatban (\pageref{table:result_scene1_multi_gpu}. oldal) jól látszódik, hogy a textúrázottság meghatározása sok időt emészt fel. Ezt GPU-ra megírva (CUDA vagy OpenCL kernel) jelentős sebességnövekedést várnék, amit érdemes lenne kivizsgálni. Ehhez viszont jobban meg kéne ismerni a heterogén párhuzamos programozás adta lehetőségeket.

Az előtér maszk meghatározása is jelentős időbe telik. Sajnos a gyorsabb MOG2 algoritmus rossz minőségű maszkokat eredményezett, bármilyen paraméterezéssel is próbálkoztam. Egy mélyrehatóbb vizsgálat lenne szükséges, hogy milyen egyéb megoldásokat lehetne itt alkalmazni, amely a teljes feldolgozás sebességét javítaná.

Érdemes lenne kipróbálni egyéb sűrű optikai folyamokat adó algoritmusokat is a meglévő mellett, hátha van olyan, ami hasonló eredményeket produkál ugyanazon hardveren kevesebb idő alatt. Erre Christopher Zach és társai \cite{zach2007duality} munkája egy jó alternatívának tűnik.

Az OpenCV új verziójában átstruktúrált OpenCL-es implementációkat is jó lenne használatba venni, ugyan a dolgozatom során megpróbálkoztam vele, de sajnos sikertelenül. Elképzelhető, hogy ez a kész 3.0-s verzióban már gond nélkül fog működni.


