%----------------------------------------------------------------------------
\chapter{Eredmények}
%----------------------------------------------------------------------------

Ebben a fejezetben az elért eredményeket összesítem, és értékelem a megoldásom.

\Aref{chapter:full-test}. fejezet elején bemutattam az első jelenetet, amit később a gyorsítási lehetőségek vizsgálatánál is felhasználtam. Ez 178 darab $640\times 480$-as felbontású képből állt, melyeken két teásdobozt mozgattam, ezek mérete összesen kb. a képek területének 15\%-át tették ki. A bemutatott képeken jól látszódott, hogy a helyreállítás minősége a mélységet bemutató színábrázolással szemléltetve nagyon jónak értékelhető, melyet az átlagos visszavetítési hibák (melyek átlaga 0,806 pixel lett) is jól alátámasztottak.

Ahogy a korábbi fejezetekben említésre került, a választott megoldáshoz szükséges, hogy az objektumok jól textúrázottak legyenek, valamint azért, hogy a különböző objektumokat elkülöníthessem, egymáshoz képest is eltérő leírókkal (alak, szín, textúra jellege) kell rendelkezniük. Ezek az én esetemben nagyjából teljesültek, egyedül az egyik teásdoboz volt néhol túl homogén, de ez jól bemutatta a megoldás ezen korlátját.

A kezdeti 1 FPS-es sebességből párhuzamosítás és GPU-n történő gyorsítás után egészen 
3,86 FPS-re sikerült gyorsítani ugyanazon jeleneten a feldolgozás sebességét, amely jelentős sebességnövekedést jelentett. Megvizsgáltam azt is, hogy kisebb képek esetén, mennyire közelíthető meg a kívánt valós idejű feldolgozás. A tesztek alapján úgy találtam, hogy az általam rendelkezésre álló hardveren a készített megoldás még az értékelhető $160\times 140$-es felbontás körüli képrészletekből jó minőségűnek mondható helyreállítást készített (ámbátor már jelentősebb, 5 pixeles átlagos visszavetítési hibával), és elérte a 12 FPS-es sebességet. Az elérni kívánt másodpercenkénti \textasciitilde 24 képkocka feldolgozását viszont nem sikerült megközelíteni, ennél kisebb képeken pedig már nem volt gyakorlati haszna kísérletezni. Ezen eredményeket összefoglalóan \aref{table:results}. táblázat mutatja be, melyen \aref{chapter:full-test}. fejezet többi jelenetének sebessége is látható a végső koncepcióval (többszálon futtatva, GPU-n is számolva).

\begin{table}[tbh]
\centering

\begin{tabular}{|l|l|l|}
\hline
\textbf{Módszer} & \textbf{Felbontás} & \textbf{Átlagos sebesség} \\ \hline\hline

1. jelenet egyszálon, CPU-n & $640\times 480$ & 1,1 FPS \\ \hline
1. jelenet többszálon, CPU-n & $640\times 480$ & 2,56 FPS \\ \hline
1. jelenet többszálon, GPU-n is & $640\times 480$ & \textbf{3,86 FPS} \\ \hline\hline
2. jelenet többszálon, GPU-n is & $640\times 480$ & \textbf{4,48 FPS} \\ \hline\hline
3. jelenet többszálon, GPU-n is & $640\times 480$ & \textbf{6,06 FPS} \\ \hline\hline

1. jelenet, eredeti kép kicsinyítve & $320\times 240$ & 10,1 FPS \\ \hline
1. jelenet, eredeti kép kicsinyítve & $160\times 120$ & \textbf{14,3 FPS} \\ \hline\hline

1. jelenet, eredeti kép egy részlete & $320\times 240$ & 7,7 FPS \\ \hline
1. jelenet, eredeti kép egy részlete & $160\times 140$ & \textbf{12 FPS} \\ \hline

\end{tabular}

\caption{Egyes módszerek és különböző felbontás esetén az átlagosan elért sebességek \label{table:results}}
\end{table}

Fontos megemlíteni, hogy a sebesség különbség az utolsó 2-2 esetben abból adódik, hogy amikor az eredeti kép egy részletét vizsgáltam, akkor a kép legnagyobb részét maga az objektum tette ki, míg a legkicsinyített verzióban csak egy kis részét.

A fentiek tükrében a kitűzött feladat megoldását sikeresnek tekintem, az elért sebesség gyakorlati körülmények között is jól használható. A következőkben a lehetséges továbbfejlesztési lehetőségekre térek ki.

%----------------------------------------------------------------------------
\section{Továbbfejlesztési lehetőségek}
%----------------------------------------------------------------------------

\Aref{table:result_scene1_multi_gpu}. táblázatban (\pageref{table:result_scene1_multi_gpu}. oldal) jól látszódik, hogy a textúrázottság meghatározása sok időt emészt fel. Ezt GPU-ra megírva (CUDA vagy OpenCL kernel segítségével) jelentős sebességnövekedést várnék, amit érdemes lenne kivizsgálni. Ehhez viszont jobban meg kéne ismerni a heterogén párhuzamos programozás adta lehetőségeket.

Az előtér maszk meghatározása is jelentős időbe telik. Sajnos a gyorsabb MOG2 algoritmus rossz minőségű maszkokat eredményezett, bármilyen paraméterezéssel is próbálkoztam. Egy mélyrehatóbb vizsgálat lenne szükséges, hogy milyen egyéb megoldásokat lehetne itt alkalmazni, amely a teljes feldolgozás sebességét javítaná.

Érdemes lenne kipróbálni egyéb sűrű optikai folyamokat adó algoritmusokat is a meglévő mellett, hátha van olyan, ami hasonló eredményeket produkál ugyanazon hardveren kevesebb idő alatt. Erre Christopher Zach és társai \cite{zach2007duality} munkája egy jó alternatívának tűnik.

Az OpenCV új verziójában átstruktúrált OpenCL-es implementációk \cite{amd-opencl-opencv} alkalmazása szintén kedvező hatással lehet a performanciára, ugyan a dolgozatom során megpróbálkoztam ezzel, de sajnos sikertelenül. Elképzelhető, hogy ez a kész 3.0-s (ami jelenleg RC1 fázisban van) verzióban már gond nélkül fog működni.
